{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>value</th>\n",
       "      <th>variable</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>2016-01-05</td>\n",
       "      <td>WLTW</td>\n",
       "      <td>added_ticker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>2016-01-05</td>\n",
       "      <td>FOSL</td>\n",
       "      <td>removed_ticker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262</th>\n",
       "      <td>2016-01-19</td>\n",
       "      <td>EXR</td>\n",
       "      <td>added_ticker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>2016-01-19</td>\n",
       "      <td>CB</td>\n",
       "      <td>removed_ticker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264</th>\n",
       "      <td>2016-02-01</td>\n",
       "      <td>FRT</td>\n",
       "      <td>added_ticker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>453</th>\n",
       "      <td>2019-12-23</td>\n",
       "      <td>ZBRA</td>\n",
       "      <td>added_ticker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>454</th>\n",
       "      <td>2019-12-23</td>\n",
       "      <td>STE</td>\n",
       "      <td>added_ticker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>449</th>\n",
       "      <td>2019-12-23</td>\n",
       "      <td>AMG</td>\n",
       "      <td>removed_ticker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>451</th>\n",
       "      <td>2019-12-23</td>\n",
       "      <td>MAC</td>\n",
       "      <td>removed_ticker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>452</th>\n",
       "      <td>2019-12-23</td>\n",
       "      <td>TRIP</td>\n",
       "      <td>removed_ticker</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>195 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          date value        variable\n",
       "261 2016-01-05  WLTW    added_ticker\n",
       "260 2016-01-05  FOSL  removed_ticker\n",
       "262 2016-01-19   EXR    added_ticker\n",
       "263 2016-01-19    CB  removed_ticker\n",
       "264 2016-02-01   FRT    added_ticker\n",
       "..         ...   ...             ...\n",
       "453 2019-12-23  ZBRA    added_ticker\n",
       "454 2019-12-23   STE    added_ticker\n",
       "449 2019-12-23   AMG  removed_ticker\n",
       "451 2019-12-23   MAC  removed_ticker\n",
       "452 2019-12-23  TRIP  removed_ticker\n",
       "\n",
       "[195 rows x 3 columns]"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "from pandas_datareader import data as pdr\n",
    "yf.pdr_override() # <== that's all it takes :-)\n",
    "import numpy as np\n",
    "import statistics\n",
    "\n",
    "sp500_history = pd.read_csv('./sp500_history.csv')\n",
    "sp500_history['date'] = pd.to_datetime(sp500_history['date']) \n",
    "sp500_history = sp500_history[['date', 'value', 'variable']]\n",
    "\n",
    "start_date = datetime.strptime('2016-1-1', '%Y-%m-%d')\n",
    "end_date = datetime.strptime('2020-12-31', '%Y-%m-%d')\n",
    "\n",
    "# greater than the start date and smaller than the end date\n",
    "mask = (sp500_history['date'] > start_date) & (sp500_history['date'] <= end_date)\n",
    "sp500_history = sp500_history.loc[mask]\n",
    "\n",
    "# Sort\n",
    "sp500_history.sort_values(['date', 'variable'], ascending=[True, True])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "calendar = pd.read_excel('./Nasdaq_Trading_Calendar.xlsx', sheet_name=None)\n",
    "rebal_dates = []\n",
    "for year in calendar:\n",
    "    sheet = calendar[year]\n",
    "    mask = sheet['S&P Indexes Rebalance S&P 500, S&P 400, and S&P 600'] == 1\n",
    "    year_rebal_dates = sheet.loc[mask]\n",
    "    for date in year_rebal_dates['Date'].values:\n",
    "        rebal_dates.append(date)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[numpy.datetime64('2020-03-20T00:00:00.000000000'),\n",
       " numpy.datetime64('2020-06-19T00:00:00.000000000'),\n",
       " numpy.datetime64('2020-09-18T00:00:00.000000000'),\n",
       " numpy.datetime64('2020-12-18T00:00:00.000000000'),\n",
       " numpy.datetime64('2019-03-15T00:00:00.000000000'),\n",
       " numpy.datetime64('2019-06-21T00:00:00.000000000'),\n",
       " numpy.datetime64('2019-09-20T00:00:00.000000000'),\n",
       " numpy.datetime64('2019-12-20T00:00:00.000000000'),\n",
       " numpy.datetime64('2018-03-16T00:00:00.000000000'),\n",
       " numpy.datetime64('2018-06-15T00:00:00.000000000'),\n",
       " numpy.datetime64('2018-09-21T00:00:00.000000000'),\n",
       " numpy.datetime64('2018-12-21T00:00:00.000000000'),\n",
       " numpy.datetime64('2017-03-17T00:00:00.000000000'),\n",
       " numpy.datetime64('2017-06-16T00:00:00.000000000'),\n",
       " numpy.datetime64('2017-09-15T00:00:00.000000000'),\n",
       " numpy.datetime64('2017-12-15T00:00:00.000000000'),\n",
       " numpy.datetime64('2016-03-18T00:00:00.000000000'),\n",
       " numpy.datetime64('2016-06-17T00:00:00.000000000'),\n",
       " numpy.datetime64('2016-09-16T00:00:00.000000000'),\n",
       " numpy.datetime64('2016-12-16T00:00:00.000000000')]"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rebal_dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_create = ['original_date', 'total', 'mean', 'std', 'up', 'count', 'max', 'min', 'sharpe', 'uppct']\n",
    "\n",
    "# output = pd.DataFrame(columns=columns_to_create)\n",
    "# output.set_index(['date', 'add/delete'])\n",
    "\n",
    "# output_add = pd.DataFrame(columns=columns_to_create)\n",
    "# output_delete = pd.DataFrame(columns=columns_to_create)\n",
    "regular_add = pd.DataFrame(columns=columns_to_create)\n",
    "regular_delete = pd.DataFrame(columns=columns_to_create)\n",
    "ad_hoc_add = pd.DataFrame(columns=columns_to_create)\n",
    "ad_hoc_delete = pd.DataFrame(columns=columns_to_create)\n",
    "\n",
    "# output_add['date'] = pd.to_datetime(output_add['date'])\n",
    "# output_add.set_index('date')\n",
    "# output_delete['date'] = pd.to_datetime(output_delete['date'])\n",
    "# output_delete.set_index('date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[-2.270000457763672]\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[-3.6821136474609375]\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[-1.19000244140625]\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[0.0]\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- BRCM: No data found for this date range, symbol may be delisted\n"
     ]
    }
   ],
   "source": [
    "MAX_DATE_EXTENSION = 10\n",
    "days_bef_aft = 10 # the range of days before and after effective date to pull from Yahoo finance\n",
    "last_date = sp500_history.iloc[0, sp500_history.columns.get_loc('date')]\n",
    "last_type = sp500_history.iloc[0, sp500_history.columns.get_loc('variable')]\n",
    "last_changes = []\n",
    "is_begin = True\n",
    "is_regular = False\n",
    "\n",
    "for idx, row in sp500_history.iterrows():\n",
    "    \n",
    "    # End date is exclusive, so need to increase by 1\n",
    "    prices = pdr.get_data_yahoo(row['value'], start=row['date'] - timedelta(days=days_bef_aft), end=row['date'] + timedelta(days=days_bef_aft + 1))\n",
    "    if len(prices) == 0:\n",
    "        continue\n",
    "        \n",
    "    # Find the adjusted effective date \n",
    "    # which is one trading day before the effective (market opening) date\n",
    "    adj_date = row['date'] - timedelta(days=1)\n",
    "    date_extension = 0\n",
    "    while not adj_date in prices.index and date_extension < MAX_DATE_EXTENSION:\n",
    "        adj_date -= timedelta(days=1)\n",
    "        date_extension += 1\n",
    "    if date_extension >= MAX_DATE_EXTENSION:\n",
    "        continue\n",
    "    adj_date_close = prices.loc[adj_date]['Close']\n",
    "    \n",
    "    if adj_date in rebal_dates:\n",
    "        is_regular = True\n",
    "    else:\n",
    "        is_regular = False\n",
    "        \n",
    "    # Find the entry date, which is one trading day before the adjusted effective date\n",
    "    prev_date = adj_date - timedelta(days=1)\n",
    "    date_extension = 0\n",
    "    while not prev_date in prices.index and date_extension < MAX_DATE_EXTENSION:\n",
    "        prev_date -= timedelta(days=1)\n",
    "        date_extension += 1\n",
    "    if date_extension >= MAX_DATE_EXTENSION:\n",
    "        continue\n",
    "    prev_close = prices.loc[prev_date]['Close']\n",
    "\n",
    "    # Find the next opening price\n",
    "#     next_date = row['date']\n",
    "#     date_extension = 0\n",
    "#     while not next_date in prices.index and date_extension < MAX_DATE_EXTENSION:\n",
    "#         next_date += timedelta(days=1)\n",
    "#         date_extension += 1\n",
    "#     if date_extension >= MAX_DATE_EXTENSION:\n",
    "#         continue    \n",
    "#     next_open = prices.loc[next_date]['Open']\n",
    "\n",
    "    price_change = adj_date_close - prev_close\n",
    "\n",
    "    # Calculate mean and all\n",
    "    if not is_begin and (last_date != adj_date or last_type != row['variable']):\n",
    "        print(last_changes)\n",
    "        count = len(last_changes)\n",
    "        mean = last_row['total'] / count\n",
    "        if count > 1:\n",
    "            std = statistics.stdev(last_changes)\n",
    "        else:\n",
    "            std = 0.000001\n",
    "        up = len(list(filter(lambda x: (x >= 0), last_changes))) \n",
    "        max_val = max(last_changes)\n",
    "        min_val = min(last_changes)\n",
    "        sharpe = mean / std * np.sqrt(252)\n",
    "        uppct = up / count\n",
    "\n",
    "        data = [mean, std, up, count, max_val, min_val, sharpe, uppct]\n",
    "\n",
    "        if last_type == 'added_ticker':\n",
    "            if is_regular:\n",
    "                regular_add.loc[last_date, 'mean':] = data\n",
    "            else:\n",
    "                ad_hoc_add.loc[last_date, 'mean':] = data\n",
    "\n",
    "        else:\n",
    "            if is_regular:\n",
    "                regular_delete.loc[last_date, 'mean':] = data\n",
    "            else:\n",
    "                ad_hoc_delete.loc[last_date, 'mean':] = data\n",
    "\n",
    "        total = 0\n",
    "        last_changes = []\n",
    "    \n",
    "    # Still in the same date\n",
    "    else:\n",
    "        if is_begin:\n",
    "            total = 0\n",
    "            is_begin = False\n",
    "        else:\n",
    "            total = last_row['total']\n",
    "    \n",
    "    total += price_change\n",
    "    \n",
    "    data = {'total': total, 'original_date': row['date']}\n",
    "            \n",
    "    if row['variable'] == 'added_ticker':\n",
    "        if is_regular:\n",
    "            if adj_date not in regular_add.index:\n",
    "                regular_add = regular_add.append(pd.DataFrame(data, index = [pd.to_datetime(adj_date)]), ignore_index=False)\n",
    "            else:\n",
    "                regular_add.loc[adj_date, 'total'] = total\n",
    "            \n",
    "        else:\n",
    "            if adj_date not in ad_hoc_add.index:\n",
    "                ad_hoc_add = ad_hoc_add.append(pd.DataFrame(data, index = [pd.to_datetime(adj_date)]), ignore_index=False)\n",
    "            else:\n",
    "                ad_hoc_add.loc[adj_date, 'total'] = total\n",
    "                \n",
    "    else:\n",
    "        if is_regular:\n",
    "            if adj_date not in regular_delete.index:\n",
    "                regular_delete = regular_delete.append(pd.DataFrame(data, index = [pd.to_datetime(adj_date)]), ignore_index=False)\n",
    "            else:\n",
    "                regular_delete.loc[adj_date, 'total'] = total\n",
    "            \n",
    "        else:\n",
    "            if adj_date not in ad_hoc_delete.index:\n",
    "                ad_hoc_delete = ad_hoc_delete.append(pd.DataFrame(data, index = [pd.to_datetime(adj_date)]), ignore_index=False)\n",
    "            else:\n",
    "                ad_hoc_delete.loc[adj_date, 'total'] = total\n",
    "                \n",
    "    last_date = adj_date\n",
    "    last_type = row['variable']\n",
    "    last_changes.append(price_change)\n",
    "    \n",
    "    if last_type == 'added_ticker':\n",
    "        if is_regular:\n",
    "            last_row = regular_add.loc[last_date, :]\n",
    "        else:\n",
    "            last_row = ad_hoc_add.loc[last_date, :]\n",
    "    \n",
    "    else:\n",
    "        if is_regular:\n",
    "            last_row = regular_delete.loc[last_date, :]\n",
    "        else:\n",
    "            last_row = ad_hoc_delete.loc[last_date, :]\n",
    "        \n",
    "regular_add.index.names = ['date']\n",
    "ad_hoc_add.index.names = ['date']\n",
    "regular_delete.index.names = ['date']\n",
    "ad_hoc_delete.index.names = ['date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2017-03-17 00:00:00')"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adj_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_add.to_csv('sp500_add.csv')\n",
    "output_delete.to_csv('sp500_delete.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
