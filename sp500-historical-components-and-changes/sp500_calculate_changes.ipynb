{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>value</th>\n",
       "      <th>variable</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>2016-01-05</td>\n",
       "      <td>WLTW</td>\n",
       "      <td>added_ticker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>2016-01-05</td>\n",
       "      <td>FOSL</td>\n",
       "      <td>removed_ticker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262</th>\n",
       "      <td>2016-01-19</td>\n",
       "      <td>EXR</td>\n",
       "      <td>added_ticker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>2016-01-19</td>\n",
       "      <td>CB</td>\n",
       "      <td>removed_ticker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264</th>\n",
       "      <td>2016-02-01</td>\n",
       "      <td>FRT</td>\n",
       "      <td>added_ticker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>453</th>\n",
       "      <td>2019-12-23</td>\n",
       "      <td>ZBRA</td>\n",
       "      <td>added_ticker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>454</th>\n",
       "      <td>2019-12-23</td>\n",
       "      <td>STE</td>\n",
       "      <td>added_ticker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>449</th>\n",
       "      <td>2019-12-23</td>\n",
       "      <td>AMG</td>\n",
       "      <td>removed_ticker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>451</th>\n",
       "      <td>2019-12-23</td>\n",
       "      <td>MAC</td>\n",
       "      <td>removed_ticker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>452</th>\n",
       "      <td>2019-12-23</td>\n",
       "      <td>TRIP</td>\n",
       "      <td>removed_ticker</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>195 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          date value        variable\n",
       "261 2016-01-05  WLTW    added_ticker\n",
       "260 2016-01-05  FOSL  removed_ticker\n",
       "262 2016-01-19   EXR    added_ticker\n",
       "263 2016-01-19    CB  removed_ticker\n",
       "264 2016-02-01   FRT    added_ticker\n",
       "..         ...   ...             ...\n",
       "453 2019-12-23  ZBRA    added_ticker\n",
       "454 2019-12-23   STE    added_ticker\n",
       "449 2019-12-23   AMG  removed_ticker\n",
       "451 2019-12-23   MAC  removed_ticker\n",
       "452 2019-12-23  TRIP  removed_ticker\n",
       "\n",
       "[195 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "from pandas_datareader import data as pdr\n",
    "yf.pdr_override() # <== that's all it takes :-)\n",
    "import numpy as np\n",
    "import statistics\n",
    "from pprint import pprint\n",
    "from math import isnan\n",
    "\n",
    "sp500_history = pd.read_csv('./sp500_history.csv')\n",
    "sp500_history['date'] = pd.to_datetime(sp500_history['date']) \n",
    "sp500_history = sp500_history[['date', 'value', 'variable']]\n",
    "\n",
    "start_date = datetime.strptime('2016-1-1', '%Y-%m-%d')\n",
    "end_date = datetime.strptime('2020-12-31', '%Y-%m-%d')\n",
    "\n",
    "# greater than the start date and smaller than the end date\n",
    "mask = (sp500_history['date'] > start_date) & (sp500_history['date'] <= end_date)\n",
    "sp500_history = sp500_history.loc[mask]\n",
    "\n",
    "# Sort\n",
    "sp500_history.sort_values(['date', 'variable'], ascending=[True, True])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[numpy.datetime64('2020-03-20T00:00:00.000000000'),\n",
      " numpy.datetime64('2020-06-19T00:00:00.000000000'),\n",
      " numpy.datetime64('2020-09-18T00:00:00.000000000'),\n",
      " numpy.datetime64('2020-12-18T00:00:00.000000000'),\n",
      " numpy.datetime64('2019-03-15T00:00:00.000000000'),\n",
      " numpy.datetime64('2019-06-21T00:00:00.000000000'),\n",
      " numpy.datetime64('2019-09-20T00:00:00.000000000'),\n",
      " numpy.datetime64('2019-12-20T00:00:00.000000000'),\n",
      " numpy.datetime64('2018-03-16T00:00:00.000000000'),\n",
      " numpy.datetime64('2018-06-15T00:00:00.000000000'),\n",
      " numpy.datetime64('2018-09-21T00:00:00.000000000'),\n",
      " numpy.datetime64('2018-12-21T00:00:00.000000000'),\n",
      " numpy.datetime64('2017-03-17T00:00:00.000000000'),\n",
      " numpy.datetime64('2017-06-16T00:00:00.000000000'),\n",
      " numpy.datetime64('2017-09-15T00:00:00.000000000'),\n",
      " numpy.datetime64('2017-12-15T00:00:00.000000000'),\n",
      " numpy.datetime64('2016-03-18T00:00:00.000000000'),\n",
      " numpy.datetime64('2016-06-17T00:00:00.000000000'),\n",
      " numpy.datetime64('2016-09-16T00:00:00.000000000'),\n",
      " numpy.datetime64('2016-12-16T00:00:00.000000000')]\n"
     ]
    }
   ],
   "source": [
    "calendar = pd.read_excel('./Nasdaq_Trading_Calendar.xlsx', sheet_name=None)\n",
    "rebal_dates = []\n",
    "for year in calendar:\n",
    "    sheet = calendar[year]\n",
    "    mask = sheet['S&P Indexes Rebalance S&P 500, S&P 400, and S&P 600'] == 1\n",
    "    year_rebal_dates = sheet.loc[mask]\n",
    "    for date in year_rebal_dates['Date'].values:\n",
    "        rebal_dates.append(date)\n",
    "pprint(rebal_dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rebal_type is 'regular' or 'ad_hoc'\n",
    "# add_delete is 'add' or 'delete'\n",
    "# entry_date and exit_date are in terms of number of days before (-) or after (+) effective date\n",
    "# entry_time and exit_time are 'Open' or 'Close'\n",
    "strategy_attributes = ['rebal_type', 'add_delete', 'entry_date', 'entry_time', 'exit_date', 'exit_time']\n",
    "\n",
    "output_columns = ['eff_date', 'original_date']\n",
    "output_columns.extend(strategy_attributes)\n",
    "output_columns.extend(['total', 'up', 'count'])\n",
    "\n",
    "df_output = pd.DataFrame(columns=output_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-93-335a3216e95e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    116\u001b[0m             \u001b[1;31m# new row\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 117\u001b[1;33m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mdf_output\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mconditions\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    118\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    119\u001b[0m \u001b[1;31m#             if len(row_to_update) == 0:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\finance\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__nonzero__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1477\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__nonzero__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1478\u001b[0m         raise ValueError(\n\u001b[1;32m-> 1479\u001b[1;33m             \u001b[1;34mf\"The truth value of a {type(self).__name__} is ambiguous. \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1480\u001b[0m             \u001b[1;34m\"Use a.empty, a.bool(), a.item(), a.any() or a.all().\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1481\u001b[0m         )\n",
      "\u001b[1;31mValueError\u001b[0m: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all()."
     ]
    }
   ],
   "source": [
    "MAX_DATE_EXTENSION = 10\n",
    "days_bef_aft = 20 # the range of days before and after effective date to pull from Yahoo finance\n",
    "# last_date = sp500_history.iloc[0, sp500_history.columns.get_loc('date')]\n",
    "# last_changes = []\n",
    "is_begin = True\n",
    "\n",
    "rebal_type = ''\n",
    "# last_rebal_type = ''\n",
    "\n",
    "add_delete = ''\n",
    "# last_add_delete = ''\n",
    "\n",
    "exit_time = 'Close'\n",
    "\n",
    "times_of_day = ['Open', 'Close']\n",
    "\n",
    "for idx, row in sp500_history.iterrows():\n",
    "    \n",
    "    # End date is exclusive, so need to increase by 1\n",
    "    prices = pdr.get_data_yahoo(row['value'], start=row['date'] - timedelta(days=days_bef_aft), end=row['date'] + timedelta(days=days_bef_aft + 1))\n",
    "    if len(prices) == 0:\n",
    "        continue\n",
    "        \n",
    "    # Find the adjusted effective date \n",
    "    # which is one trading day before the wikipedia effective (i.e. market opening) date\n",
    "    eff_date_index = prices.index.get_loc(row['date'],method='pad')\n",
    "    if eff_date_index < 0:\n",
    "        print('SOMETHINGS WRONG')\n",
    "        print(prices)\n",
    "        print(row['date'])\n",
    "        continue\n",
    "    eff_date = prices.iloc[eff_date_index].name\n",
    "        \n",
    "        \n",
    "    '''\n",
    "    Loop of different entry and exit dates\n",
    "    '''\n",
    "    entry_date = max(-4, -eff_date_index)\n",
    "#     exit_date = min(4, len(prices) - 1)\n",
    "    exit_date = 0\n",
    "    while entry_date <= 0:\n",
    "        for time_of_day in times_of_day:\n",
    "            entry_time = time_of_day\n",
    "                    \n",
    "            # Find the entry price\n",
    "            entry_date_index = eff_date_index + entry_date\n",
    "            if entry_date_index < 0:\n",
    "                continue\n",
    "            entry_price = prices.iloc[entry_date_index][entry_time]\n",
    "            if isnan(entry_price):\n",
    "                continue\n",
    "\n",
    "            # Find the exit price\n",
    "            exit_date_index = eff_date_index + exit_date\n",
    "            if exit_date_index >= len(prices):\n",
    "                continue\n",
    "            exit_price = prices.iloc[exit_date_index][exit_time]\n",
    "            if isnan(exit_price):\n",
    "                continue\n",
    "\n",
    "            price_change = exit_price / entry_price - 1 # percentage change in price between entry and exit\n",
    "\n",
    "            if eff_date in rebal_dates:\n",
    "                rebal_type = 'regular'\n",
    "            else:\n",
    "                rebal_type = 'ad_hoc'\n",
    "\n",
    "            if row['variable'] == 'added_ticker':\n",
    "                add_delete = 'add'\n",
    "            else:\n",
    "                add_delete = 'delete'\n",
    "\n",
    "            # Calculate mean and all\n",
    "#             if not is_begin and (last_date != eff_date or last_add_delete != add_delete):\n",
    "#                 count = len(last_changes)\n",
    "#                 up = len(list(filter(lambda x: (x >= 0), last_changes))) \n",
    "\n",
    "#                 data = [up, count]\n",
    "\n",
    "#                 df_output.loc[(df_output['eff_date']==last_date) & \n",
    "#                          (df_output['rebal_type']==last_rebal_type) & \n",
    "#                          (df_output['add_delete']==last_add_delete), 'up':] = data\n",
    "\n",
    "#                 total = 0\n",
    "#                 last_changes = []\n",
    "\n",
    "#             Still in the same date\n",
    "#             else:\n",
    "#             if is_begin:\n",
    "#                 total = 0\n",
    "#                 is_begin = False\n",
    "#             else:\n",
    "#                 total = last_row['total']\n",
    "\n",
    "#             total += price_change\n",
    "\n",
    "#             data = [{'eff_date': eff_date, 'rebal_type': rebal_type, 'add_delete': add_delete, \n",
    "#                      'entry_date': entry_date, 'entry_time': entry_time, \n",
    "#                      'exit_date': exit_date, 'exit_time': exit_time, \n",
    "#                      'total': total, 'original_date': row['date']}]\n",
    "            if price_change > 0:\n",
    "                up = 1\n",
    "            else:\n",
    "                up = 0\n",
    "          \n",
    "            conditions = ((df_output['eff_date']==eff_date) & \n",
    "                         (df_output['rebal_type']==rebal_type) & \n",
    "                         (df_output['add_delete']==add_delete) &\n",
    "                        (df_output['entry_date']==entry_date) & \n",
    "                        (df_output['entry_time']==entry_time) & \n",
    "                        (df_output['exit_date']==exit_date) & \n",
    "                        (df_output['exit_time']==exit_time))\n",
    "                        \n",
    "#             row_to_update = df_output[conditions]\n",
    "\n",
    "            # new row\n",
    "            if not (df_output[conditions]).any():\n",
    "                \n",
    "#             if len(row_to_update) == 0:\n",
    "                data = [{'eff_date': eff_date, 'rebal_type': rebal_type, 'add_delete': add_delete, \n",
    "                         'entry_date': entry_date, 'entry_time': entry_time, \n",
    "                         'exit_date': exit_date, 'exit_time': exit_time, \n",
    "                         'total': price_change, 'up': up, 'count': 1, 'original_date': row['date']}]\n",
    "                df_output = df_output.append(pd.DataFrame(data), ignore_index=True)\n",
    "            \n",
    "            # updating existing row\n",
    "            else:\n",
    "#                 row_to_update = df_output[df_output['eff_date']==eff_date]\n",
    "                df_output.loc[conditions, 'total'] += price_change\n",
    "                df_output.loc[conditions, 'up'] += up\n",
    "                df_output.loc[conditions, 'count'] += 1\n",
    "\n",
    "#                 row_to_update['total'] += price_change\n",
    "#                 row_to_update['up'] += up\n",
    "#                 row_to_update['count'] += 1\n",
    "\n",
    "        entry_date += 1\n",
    "\n",
    "#     last_date = eff_date\n",
    "#     last_changes.append(price_change)\n",
    "#     last_add_delete = add_delete\n",
    "#     last_rebal_type = rebal_type\n",
    "#     last_row = df_output[(df_output['eff_date']==last_date) & \n",
    "#                          (df_output['rebal_type']==rebal_type) & \n",
    "#                          (df_output['add_delete']==add_delete)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "conditions = ((df_output['eff_date']==eff_date) & \n",
    "(df_output['rebal_type']==rebal_type) & \n",
    "(df_output['add_delete']==add_delete) &\n",
    "(df_output['entry_date']==entry_date) & \n",
    "(df_output['entry_time']==entry_time) & \n",
    "(df_output['exit_date']==exit_date) & \n",
    "(df_output['exit_time']==exit_time))\n",
    "\n",
    "row_to_update = df_output[conditions]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eff_date</th>\n",
       "      <th>original_date</th>\n",
       "      <th>rebal_type</th>\n",
       "      <th>add_delete</th>\n",
       "      <th>entry_date</th>\n",
       "      <th>entry_time</th>\n",
       "      <th>exit_date</th>\n",
       "      <th>exit_time</th>\n",
       "      <th>total</th>\n",
       "      <th>up</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [eff_date, original_date, rebal_type, add_delete, entry_date, entry_time, exit_date, exit_time, total, up, count]\n",
       "Index: []"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row_to_update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_output.loc[conditions, 'total'] = 'haha'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conditions.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_uniques(input_list):\n",
    "    # insert the list to the set \n",
    "    unique_set = set(input_list) \n",
    "    # convert the set to the list \n",
    "    unique_list = (list(unique_set)) \n",
    "    return unique_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yingchen\\Anaconda3\\envs\\finance\\lib\\site-packages\\ipykernel_launcher.py:25: RuntimeWarning: invalid value encountered in double_scalars\n",
      "C:\\Users\\Yingchen\\Anaconda3\\envs\\finance\\lib\\site-packages\\ipykernel_launcher.py:36: RuntimeWarning: invalid value encountered in double_scalars\n",
      "C:\\Users\\Yingchen\\Anaconda3\\envs\\finance\\lib\\site-packages\\ipykernel_launcher.py:25: RuntimeWarning: divide by zero encountered in double_scalars\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Calculate population statistics\n",
    "'''\n",
    "\n",
    "stats_df_columns = []\n",
    "stats_df_columns.extend(strategy_attributes)\n",
    "stats_df_columns.extend(['total', 'up', 'count', 'mean', 'std', 'max', 'min', 'sharpe', 'uppct'])\n",
    "\n",
    "stats_df = pd.DataFrame(columns=stats_df_columns)\n",
    "\n",
    "# get the unique values for each strategy attribute\n",
    "strategy_attribute_unique_values = map(lambda strategy_attribute: get_uniques(df_output[strategy_attribute]), strategy_attributes)   \n",
    "\n",
    "import itertools\n",
    "# find strategies consisting of different combinations of unique values for each strategy attribute\n",
    "strategies = list(itertools.product(*strategy_attribute_unique_values)) \n",
    "\n",
    "for strategy in strategies:\n",
    "    # find the relevant rows for each strategy \n",
    "    relevant_rows = df_output.loc[(df_output[strategy_attributes]==strategy).all(axis=1), :]\n",
    "    if len(relevant_rows) == 0:\n",
    "        continue\n",
    "    \n",
    "    relevant_rows_sum = relevant_rows.loc[:, 'total':].sum(axis=0)\n",
    "    mean = relevant_rows_sum['total'] / relevant_rows_sum['count']\n",
    "    if relevant_rows_sum['count'] > 1:\n",
    "        std = statistics.stdev(relevant_rows['total'])\n",
    "    else:\n",
    "        std = 0\n",
    "    max_val = max(relevant_rows['total'])\n",
    "    min_val = min(relevant_rows['total'])\n",
    "    if std == 0:\n",
    "        sharpe = mean / 0.00001 * np.sqrt(252)\n",
    "    else:\n",
    "        sharpe = mean / std * np.sqrt(252)\n",
    "    uppct = relevant_rows_sum['up'] / relevant_rows_sum['count']\n",
    "    strategy_dict = dict(zip(strategy_attributes, strategy)) \n",
    "    data = {'total': relevant_rows_sum['total'], 'up': relevant_rows_sum['up'], 'count': relevant_rows_sum['count'], \n",
    "            'mean': mean, 'std': std, 'max': max_val, 'min': min_val, 'sharpe': sharpe, 'uppct': uppct} \n",
    "    data.update(strategy_dict)\n",
    "    stats_df = stats_df.append(pd.DataFrame([data]), ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Writing to excel\n",
    "'''\n",
    "writer = pd.ExcelWriter('sp500_analysis.xlsx', engine='xlsxwriter')\n",
    "df_output.to_excel(writer, sheet_name='data')\n",
    "stats_df.to_excel(writer, sheet_name='strategy_stats')\n",
    "writer.save()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
