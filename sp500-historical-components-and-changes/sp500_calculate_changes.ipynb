{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>value</th>\n",
       "      <th>variable</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>2016-01-05</td>\n",
       "      <td>WLTW</td>\n",
       "      <td>added_ticker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>2016-01-05</td>\n",
       "      <td>FOSL</td>\n",
       "      <td>removed_ticker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262</th>\n",
       "      <td>2016-01-19</td>\n",
       "      <td>EXR</td>\n",
       "      <td>added_ticker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>2016-01-19</td>\n",
       "      <td>CB</td>\n",
       "      <td>removed_ticker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264</th>\n",
       "      <td>2016-02-01</td>\n",
       "      <td>FRT</td>\n",
       "      <td>added_ticker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>453</th>\n",
       "      <td>2019-12-23</td>\n",
       "      <td>ZBRA</td>\n",
       "      <td>added_ticker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>454</th>\n",
       "      <td>2019-12-23</td>\n",
       "      <td>STE</td>\n",
       "      <td>added_ticker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>449</th>\n",
       "      <td>2019-12-23</td>\n",
       "      <td>AMG</td>\n",
       "      <td>removed_ticker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>451</th>\n",
       "      <td>2019-12-23</td>\n",
       "      <td>MAC</td>\n",
       "      <td>removed_ticker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>452</th>\n",
       "      <td>2019-12-23</td>\n",
       "      <td>TRIP</td>\n",
       "      <td>removed_ticker</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>195 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          date value        variable\n",
       "261 2016-01-05  WLTW    added_ticker\n",
       "260 2016-01-05  FOSL  removed_ticker\n",
       "262 2016-01-19   EXR    added_ticker\n",
       "263 2016-01-19    CB  removed_ticker\n",
       "264 2016-02-01   FRT    added_ticker\n",
       "..         ...   ...             ...\n",
       "453 2019-12-23  ZBRA    added_ticker\n",
       "454 2019-12-23   STE    added_ticker\n",
       "449 2019-12-23   AMG  removed_ticker\n",
       "451 2019-12-23   MAC  removed_ticker\n",
       "452 2019-12-23  TRIP  removed_ticker\n",
       "\n",
       "[195 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "from pandas_datareader import data as pdr\n",
    "yf.pdr_override() # <== that's all it takes :-)\n",
    "import numpy as np\n",
    "import statistics\n",
    "from pprint import pprint\n",
    "from math import isnan\n",
    "\n",
    "sp500_history = pd.read_csv('./sp500_history.csv')\n",
    "sp500_history['date'] = pd.to_datetime(sp500_history['date']) \n",
    "sp500_history = sp500_history[['date', 'value', 'variable']]\n",
    "\n",
    "start_date = datetime.strptime('2016-1-1', '%Y-%m-%d')\n",
    "end_date = datetime.strptime('2020-12-31', '%Y-%m-%d')\n",
    "\n",
    "# greater than the start date and smaller than the end date\n",
    "mask = (sp500_history['date'] > start_date) & (sp500_history['date'] <= end_date)\n",
    "sp500_history = sp500_history.loc[mask]\n",
    "\n",
    "# Sort\n",
    "sp500_history.sort_values(['date', 'variable'], ascending=[True, True])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[numpy.datetime64('2020-03-20T00:00:00.000000000'),\n",
      " numpy.datetime64('2020-06-19T00:00:00.000000000'),\n",
      " numpy.datetime64('2020-09-18T00:00:00.000000000'),\n",
      " numpy.datetime64('2020-12-18T00:00:00.000000000'),\n",
      " numpy.datetime64('2019-03-15T00:00:00.000000000'),\n",
      " numpy.datetime64('2019-06-21T00:00:00.000000000'),\n",
      " numpy.datetime64('2019-09-20T00:00:00.000000000'),\n",
      " numpy.datetime64('2019-12-20T00:00:00.000000000'),\n",
      " numpy.datetime64('2018-03-16T00:00:00.000000000'),\n",
      " numpy.datetime64('2018-06-15T00:00:00.000000000'),\n",
      " numpy.datetime64('2018-09-21T00:00:00.000000000'),\n",
      " numpy.datetime64('2018-12-21T00:00:00.000000000'),\n",
      " numpy.datetime64('2017-03-17T00:00:00.000000000'),\n",
      " numpy.datetime64('2017-06-16T00:00:00.000000000'),\n",
      " numpy.datetime64('2017-09-15T00:00:00.000000000'),\n",
      " numpy.datetime64('2017-12-15T00:00:00.000000000'),\n",
      " numpy.datetime64('2016-03-18T00:00:00.000000000'),\n",
      " numpy.datetime64('2016-06-17T00:00:00.000000000'),\n",
      " numpy.datetime64('2016-09-16T00:00:00.000000000'),\n",
      " numpy.datetime64('2016-12-16T00:00:00.000000000')]\n"
     ]
    }
   ],
   "source": [
    "calendar = pd.read_excel('./Nasdaq_Trading_Calendar.xlsx', sheet_name=None)\n",
    "rebal_dates = []\n",
    "for year in calendar:\n",
    "    sheet = calendar[year]\n",
    "    mask = sheet['S&P Indexes Rebalance S&P 500, S&P 400, and S&P 600'] == 1\n",
    "    year_rebal_dates = sheet.loc[mask]\n",
    "    for date in year_rebal_dates['Date'].values:\n",
    "        rebal_dates.append(date)\n",
    "pprint(rebal_dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rebal_type is 'regular' or 'ad_hoc'\n",
    "# add_delete is 'add' or 'delete'\n",
    "# entry_date and exit_date are in terms of number of days before (-) or after (+) effective date\n",
    "# entry_time and exit_time are 'Open' or 'Close'\n",
    "strategy_attributes = ['rebal_type', 'add_delete', 'entry_date', 'entry_time', 'exit_date', 'exit_time']\n",
    "\n",
    "output_columns = ['eff_date', 'original_date']\n",
    "output_columns.extend(strategy_attributes)\n",
    "output_columns.extend(['total', 'up', 'count'])\n",
    "\n",
    "df_output = pd.DataFrame(columns=output_columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yingchen\\Anaconda3\\envs\\finance\\lib\\site-packages\\ipykernel_launcher.py:95: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- BRCM: No data found for this date range, symbol may be delisted\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- PCP: Data doesn't exist for startDate = 1452528000, endDate = 1456070400\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- GMCR: No data found for this date range, symbol may be delisted\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- ESV: No data found, symbol may be delisted\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- CAM: No data found for this date range, symbol may be delisted\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- ADT: Data doesn't exist for startDate = 1460476800, endDate = 1464019200\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- SNDK: No data found for this date range, symbol may be delisted\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- TWC: No data found for this date range, symbol may be delisted\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- ARG: Data doesn't exist for startDate = 1462204800, endDate = 1465747200\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- CCE: Data doesn't exist for startDate = 1462896000, endDate = 1466438400\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- BXLT: No data found for this date range, symbol may be delisted\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- CVC: No data found for this date range, symbol may be delisted\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- TE: No data found for this date range, symbol may be delisted\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- CPGX: No data found for this date range, symbol may be delisted\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- STJ: No data found for this date range, symbol may be delisted\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- SE: Data doesn't exist for startDate = 1486483200, endDate = 1490025600\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- LLTC: No data found for this date range, symbol may be delisted\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- MJN: No data found for this date range, symbol may be delisted\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- YHOO: No data found for this date range, symbol may be delisted\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- RAI: No data found for this date range, symbol may be delisted\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- WFM: No data found for this date range, symbol may be delisted\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- Q: No data found for this date range, symbol may be delisted\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- SPLS: No data found for this date range, symbol may be delisted\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- LVLT: No data found for this date range, symbol may be delisted\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- BCR: No data found for this date range, symbol may be delisted\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- WYN: No data found for this date range, symbol may be delisted\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- DPS: No data found for this date range, symbol may be delisted\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- GGP: No data found for this date range, symbol may be delisted\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- BMS: No data found, symbol may be delisted\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- LLL: No data found, symbol may be delisted\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- RHT: No data found, symbol may be delisted\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- APC: No data found, symbol may be delisted\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- TSS: No data found, symbol may be delisted\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "MAX_DATE_EXTENSION = 10\n",
    "days_bef_aft = 20 # the range of days before and after effective date to pull from Yahoo finance\n",
    "last_date = sp500_history.iloc[0, sp500_history.columns.get_loc('date')]\n",
    "last_changes = []\n",
    "is_begin = True\n",
    "\n",
    "rebal_type = ''\n",
    "last_rebal_type = ''\n",
    "\n",
    "add_delete = ''\n",
    "last_add_delete = ''\n",
    "\n",
    "entry_date = -1\n",
    "entry_time = 'Close'\n",
    "exit_date = 0\n",
    "exit_time = 'Close'\n",
    "\n",
    "for idx, row in sp500_history.iterrows():\n",
    "    \n",
    "    # End date is exclusive, so need to increase by 1\n",
    "    prices = pdr.get_data_yahoo(row['value'], start=row['date'] - timedelta(days=days_bef_aft), end=row['date'] + timedelta(days=days_bef_aft + 1))\n",
    "    if len(prices) == 0:\n",
    "        continue\n",
    "        \n",
    "    if row['date'] not in prices.index:\n",
    "        print('SOMETHINGS WRONG')\n",
    "        break\n",
    "        \n",
    "    # Find the adjusted effective date \n",
    "    # which is one trading day before the wikipedia effective (i.e. market opening) date\n",
    "    eff_date = row['date'] - timedelta(days=1)\n",
    "    date_extension = 0\n",
    "    while not eff_date in prices.index and date_extension < MAX_DATE_EXTENSION:\n",
    "        eff_date -= timedelta(days=1)\n",
    "        date_extension += 1\n",
    "    if date_extension >= MAX_DATE_EXTENSION:\n",
    "        continue\n",
    "    eff_date_close = prices.loc[eff_date][entry_time]\n",
    "    if isnan(eff_date_close):\n",
    "        continue\n",
    "        \n",
    "    # Find the entry date, which is one trading day before the adjusted effective date\n",
    "    prev_date = eff_date - timedelta(days=1)\n",
    "    date_extension = 0\n",
    "    while not prev_date in prices.index and date_extension < MAX_DATE_EXTENSION:\n",
    "        prev_date -= timedelta(days=1)\n",
    "        date_extension += 1\n",
    "    if date_extension >= MAX_DATE_EXTENSION:\n",
    "        continue\n",
    "    prev_close = prices.loc[prev_date][exit_time]\n",
    "    if isnan(prev_close):\n",
    "        continue\n",
    "\n",
    "    price_change = eff_date_close / prev_close - 1 # percentage change in price between entry and exit\n",
    "    \n",
    "    if eff_date in rebal_dates:\n",
    "        rebal_type = 'regular'\n",
    "            \n",
    "    else:\n",
    "        rebal_type = 'ad_hoc'\n",
    "\n",
    "    if row['variable'] == 'added_ticker':\n",
    "        add_delete = 'add'\n",
    "    else:\n",
    "        add_delete = 'delete'\n",
    "\n",
    "    # Calculate mean and all\n",
    "    if not is_begin and (last_date != eff_date or last_add_delete != add_delete):\n",
    "        count = len(last_changes)\n",
    "        up = len(list(filter(lambda x: (x >= 0), last_changes))) \n",
    "        \n",
    "        data = [up, count]\n",
    "\n",
    "        df_output.loc[(df_output['eff_date']==last_date) & \n",
    "                 (df_output['rebal_type']==last_rebal_type) & \n",
    "                 (df_output['add_delete']==last_add_delete), 'up':] = data\n",
    "\n",
    "        total = 0\n",
    "        last_changes = []\n",
    "    \n",
    "    # Still in the same date\n",
    "    else:\n",
    "        if is_begin:\n",
    "            total = 0\n",
    "            is_begin = False\n",
    "        else:\n",
    "            total = last_row['total']\n",
    "    \n",
    "    total += price_change\n",
    "    \n",
    "    data = [{'eff_date': pd.to_datetime(eff_date), 'rebal_type': rebal_type, 'add_delete': add_delete, \n",
    "             'entry_date': entry_date, 'entry_time': entry_time, \n",
    "             'exit_date': exit_date, 'exit_time': exit_time, \n",
    "             'total': total, 'original_date': row['date']}]\n",
    "            \n",
    "    if not (df_output['eff_date']==eff_date).any():\n",
    "        df_output = df_output.append(pd.DataFrame(data), ignore_index=True)\n",
    "    else:\n",
    "        df_output[df_output['eff_date']==eff_date]['total'] = total\n",
    "\n",
    "    last_date = eff_date\n",
    "    last_changes.append(price_change)\n",
    "    last_add_delete = add_delete\n",
    "    last_rebal_type = rebal_type\n",
    "    last_row = df_output[(df_output['eff_date']==last_date) & \n",
    "                         (df_output['rebal_type']==rebal_type) & \n",
    "                         (df_output['add_delete']==add_delete)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-12-02</th>\n",
       "      <td>151.990005</td>\n",
       "      <td>151.990005</td>\n",
       "      <td>149.339996</td>\n",
       "      <td>150.240005</td>\n",
       "      <td>149.909027</td>\n",
       "      <td>308100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-03</th>\n",
       "      <td>149.740005</td>\n",
       "      <td>152.399994</td>\n",
       "      <td>149.449997</td>\n",
       "      <td>152.080002</td>\n",
       "      <td>151.744965</td>\n",
       "      <td>406900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-04</th>\n",
       "      <td>152.509995</td>\n",
       "      <td>154.300003</td>\n",
       "      <td>152.509995</td>\n",
       "      <td>154.070007</td>\n",
       "      <td>153.730591</td>\n",
       "      <td>473400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-05</th>\n",
       "      <td>153.619995</td>\n",
       "      <td>153.929993</td>\n",
       "      <td>152.589996</td>\n",
       "      <td>152.949997</td>\n",
       "      <td>152.613037</td>\n",
       "      <td>338700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-06</th>\n",
       "      <td>154.000000</td>\n",
       "      <td>155.070007</td>\n",
       "      <td>153.669998</td>\n",
       "      <td>154.300003</td>\n",
       "      <td>153.960068</td>\n",
       "      <td>340800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-09</th>\n",
       "      <td>153.669998</td>\n",
       "      <td>154.130005</td>\n",
       "      <td>152.350006</td>\n",
       "      <td>152.539993</td>\n",
       "      <td>152.203934</td>\n",
       "      <td>279300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-10</th>\n",
       "      <td>152.940002</td>\n",
       "      <td>154.020004</td>\n",
       "      <td>151.779999</td>\n",
       "      <td>153.940002</td>\n",
       "      <td>153.600861</td>\n",
       "      <td>304100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-11</th>\n",
       "      <td>154.320007</td>\n",
       "      <td>155.000000</td>\n",
       "      <td>153.199997</td>\n",
       "      <td>153.679993</td>\n",
       "      <td>153.341431</td>\n",
       "      <td>440000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-12</th>\n",
       "      <td>154.179993</td>\n",
       "      <td>154.399994</td>\n",
       "      <td>152.300003</td>\n",
       "      <td>153.660004</td>\n",
       "      <td>153.321487</td>\n",
       "      <td>410400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-13</th>\n",
       "      <td>153.119995</td>\n",
       "      <td>153.979996</td>\n",
       "      <td>151.529999</td>\n",
       "      <td>151.929993</td>\n",
       "      <td>151.595291</td>\n",
       "      <td>503200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-16</th>\n",
       "      <td>152.289993</td>\n",
       "      <td>152.850006</td>\n",
       "      <td>149.580002</td>\n",
       "      <td>150.750000</td>\n",
       "      <td>150.417892</td>\n",
       "      <td>1253500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-17</th>\n",
       "      <td>150.610001</td>\n",
       "      <td>151.899994</td>\n",
       "      <td>149.380005</td>\n",
       "      <td>151.520004</td>\n",
       "      <td>151.186203</td>\n",
       "      <td>758900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-18</th>\n",
       "      <td>152.080002</td>\n",
       "      <td>152.399994</td>\n",
       "      <td>148.389999</td>\n",
       "      <td>149.259995</td>\n",
       "      <td>148.931168</td>\n",
       "      <td>753900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-19</th>\n",
       "      <td>149.309998</td>\n",
       "      <td>149.710007</td>\n",
       "      <td>147.240005</td>\n",
       "      <td>148.389999</td>\n",
       "      <td>148.063095</td>\n",
       "      <td>1200200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-20</th>\n",
       "      <td>149.449997</td>\n",
       "      <td>151.919998</td>\n",
       "      <td>148.520004</td>\n",
       "      <td>149.839996</td>\n",
       "      <td>149.509888</td>\n",
       "      <td>14904400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-23</th>\n",
       "      <td>150.100006</td>\n",
       "      <td>152.860001</td>\n",
       "      <td>149.600006</td>\n",
       "      <td>151.479996</td>\n",
       "      <td>151.146271</td>\n",
       "      <td>786300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-24</th>\n",
       "      <td>151.610001</td>\n",
       "      <td>152.080002</td>\n",
       "      <td>150.919998</td>\n",
       "      <td>152.029999</td>\n",
       "      <td>151.695068</td>\n",
       "      <td>137700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-26</th>\n",
       "      <td>152.179993</td>\n",
       "      <td>152.839996</td>\n",
       "      <td>150.600006</td>\n",
       "      <td>151.350006</td>\n",
       "      <td>151.016571</td>\n",
       "      <td>649300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-27</th>\n",
       "      <td>151.960007</td>\n",
       "      <td>152.380005</td>\n",
       "      <td>150.490005</td>\n",
       "      <td>151.809998</td>\n",
       "      <td>151.475555</td>\n",
       "      <td>433400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-30</th>\n",
       "      <td>152.119995</td>\n",
       "      <td>152.940002</td>\n",
       "      <td>151.419998</td>\n",
       "      <td>151.940002</td>\n",
       "      <td>151.605270</td>\n",
       "      <td>600500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-31</th>\n",
       "      <td>151.910004</td>\n",
       "      <td>152.559998</td>\n",
       "      <td>151.259995</td>\n",
       "      <td>152.419998</td>\n",
       "      <td>152.084213</td>\n",
       "      <td>330200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-02</th>\n",
       "      <td>152.580002</td>\n",
       "      <td>153.210007</td>\n",
       "      <td>150.529999</td>\n",
       "      <td>151.699997</td>\n",
       "      <td>151.365799</td>\n",
       "      <td>641200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-03</th>\n",
       "      <td>149.429993</td>\n",
       "      <td>151.500000</td>\n",
       "      <td>149.199997</td>\n",
       "      <td>150.630005</td>\n",
       "      <td>150.298157</td>\n",
       "      <td>638000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-06</th>\n",
       "      <td>150.500000</td>\n",
       "      <td>152.130005</td>\n",
       "      <td>150.229996</td>\n",
       "      <td>151.619995</td>\n",
       "      <td>151.285965</td>\n",
       "      <td>581900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-07</th>\n",
       "      <td>150.710007</td>\n",
       "      <td>151.710007</td>\n",
       "      <td>150.610001</td>\n",
       "      <td>151.039993</td>\n",
       "      <td>150.707245</td>\n",
       "      <td>429900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-08</th>\n",
       "      <td>151.600006</td>\n",
       "      <td>152.009995</td>\n",
       "      <td>150.419998</td>\n",
       "      <td>150.949997</td>\n",
       "      <td>150.617447</td>\n",
       "      <td>839000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-09</th>\n",
       "      <td>151.550003</td>\n",
       "      <td>153.160004</td>\n",
       "      <td>151.300003</td>\n",
       "      <td>151.779999</td>\n",
       "      <td>151.445618</td>\n",
       "      <td>644100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-10</th>\n",
       "      <td>152.389999</td>\n",
       "      <td>152.529999</td>\n",
       "      <td>150.509995</td>\n",
       "      <td>151.009995</td>\n",
       "      <td>150.677307</td>\n",
       "      <td>432000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Open        High         Low       Close   Adj Close  \\\n",
       "Date                                                                     \n",
       "2019-12-02  151.990005  151.990005  149.339996  150.240005  149.909027   \n",
       "2019-12-03  149.740005  152.399994  149.449997  152.080002  151.744965   \n",
       "2019-12-04  152.509995  154.300003  152.509995  154.070007  153.730591   \n",
       "2019-12-05  153.619995  153.929993  152.589996  152.949997  152.613037   \n",
       "2019-12-06  154.000000  155.070007  153.669998  154.300003  153.960068   \n",
       "2019-12-09  153.669998  154.130005  152.350006  152.539993  152.203934   \n",
       "2019-12-10  152.940002  154.020004  151.779999  153.940002  153.600861   \n",
       "2019-12-11  154.320007  155.000000  153.199997  153.679993  153.341431   \n",
       "2019-12-12  154.179993  154.399994  152.300003  153.660004  153.321487   \n",
       "2019-12-13  153.119995  153.979996  151.529999  151.929993  151.595291   \n",
       "2019-12-16  152.289993  152.850006  149.580002  150.750000  150.417892   \n",
       "2019-12-17  150.610001  151.899994  149.380005  151.520004  151.186203   \n",
       "2019-12-18  152.080002  152.399994  148.389999  149.259995  148.931168   \n",
       "2019-12-19  149.309998  149.710007  147.240005  148.389999  148.063095   \n",
       "2019-12-20  149.449997  151.919998  148.520004  149.839996  149.509888   \n",
       "2019-12-23  150.100006  152.860001  149.600006  151.479996  151.146271   \n",
       "2019-12-24  151.610001  152.080002  150.919998  152.029999  151.695068   \n",
       "2019-12-26  152.179993  152.839996  150.600006  151.350006  151.016571   \n",
       "2019-12-27  151.960007  152.380005  150.490005  151.809998  151.475555   \n",
       "2019-12-30  152.119995  152.940002  151.419998  151.940002  151.605270   \n",
       "2019-12-31  151.910004  152.559998  151.259995  152.419998  152.084213   \n",
       "2020-01-02  152.580002  153.210007  150.529999  151.699997  151.365799   \n",
       "2020-01-03  149.429993  151.500000  149.199997  150.630005  150.298157   \n",
       "2020-01-06  150.500000  152.130005  150.229996  151.619995  151.285965   \n",
       "2020-01-07  150.710007  151.710007  150.610001  151.039993  150.707245   \n",
       "2020-01-08  151.600006  152.009995  150.419998  150.949997  150.617447   \n",
       "2020-01-09  151.550003  153.160004  151.300003  151.779999  151.445618   \n",
       "2020-01-10  152.389999  152.529999  150.509995  151.009995  150.677307   \n",
       "\n",
       "              Volume  \n",
       "Date                  \n",
       "2019-12-02    308100  \n",
       "2019-12-03    406900  \n",
       "2019-12-04    473400  \n",
       "2019-12-05    338700  \n",
       "2019-12-06    340800  \n",
       "2019-12-09    279300  \n",
       "2019-12-10    304100  \n",
       "2019-12-11    440000  \n",
       "2019-12-12    410400  \n",
       "2019-12-13    503200  \n",
       "2019-12-16   1253500  \n",
       "2019-12-17    758900  \n",
       "2019-12-18    753900  \n",
       "2019-12-19   1200200  \n",
       "2019-12-20  14904400  \n",
       "2019-12-23    786300  \n",
       "2019-12-24    137700  \n",
       "2019-12-26    649300  \n",
       "2019-12-27    433400  \n",
       "2019-12-30    600500  \n",
       "2019-12-31    330200  \n",
       "2020-01-02    641200  \n",
       "2020-01-03    638000  \n",
       "2020-01-06    581900  \n",
       "2020-01-07    429900  \n",
       "2020-01-08    839000  \n",
       "2020-01-09    644100  \n",
       "2020-01-10    432000  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_uniques(input_list):\n",
    "    # insert the list to the set \n",
    "    unique_set = set(input_list) \n",
    "    # convert the set to the list \n",
    "    unique_list = (list(unique_set)) \n",
    "    return unique_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Calculate population statistics\n",
    "'''\n",
    "\n",
    "stats_df_columns = []\n",
    "stats_df_columns.extend(strategy_attributes)\n",
    "stats_df_columns.extend(['total', 'up', 'count', 'mean', 'std', 'max', 'min', 'sharpe', 'uppct'])\n",
    "\n",
    "stats_df = pd.DataFrame(columns=stats_df_columns)\n",
    "\n",
    "# get the unique values for each strategy attribute\n",
    "strategy_attribute_unique_values = map(lambda strategy_attribute: get_uniques(df_output[strategy_attribute]), strategy_attributes)   \n",
    "\n",
    "import itertools\n",
    "# find strategies consisting of different combinations of unique values for each strategy attribute\n",
    "strategies = list(itertools.product(*strategy_attribute_unique_values)) \n",
    "\n",
    "for strategy in strategies:\n",
    "    # find the relevant rows for each strategy \n",
    "    relevant_rows = df_output.loc[(df_output[strategy_attributes]==strategy).all(axis=1), :]\n",
    "    \n",
    "    relevant_rows_sum = relevant_rows.loc[:, 'total':].sum(axis=0)\n",
    "    mean = relevant_rows_sum['total'] / relevant_rows_sum['count']\n",
    "    if relevant_rows_sum['count'] > 1:\n",
    "        std = statistics.stdev(relevant_rows['total'])\n",
    "    else:\n",
    "        std = 0\n",
    "    max_val = max(relevant_rows['total'])\n",
    "    min_val = min(relevant_rows['total'])\n",
    "    if std == 0:\n",
    "        sharpe = mean / 0.00001 * np.sqrt(252)\n",
    "    else:\n",
    "        sharpe = mean / std * np.sqrt(252)\n",
    "    uppct = relevant_rows_sum['up'] / relevant_rows_sum['count']\n",
    "    strategy_dict = dict(zip(strategy_attributes, strategy)) \n",
    "    data = {'total': relevant_rows_sum['total'], 'up': relevant_rows_sum['up'], 'count': relevant_rows_sum['count'], \n",
    "            'mean': mean, 'std': std, 'max': max_val, 'min': min_val, 'sharpe': sharpe, 'uppct': uppct} \n",
    "    data.update(strategy_dict)\n",
    "    stats_df = stats_df.append(pd.DataFrame([data]), ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Writing to excel\n",
    "'''\n",
    "writer = pd.ExcelWriter('sp500_analysis.xlsx', engine='xlsxwriter')\n",
    "df_output.to_excel(writer, sheet_name='data')\n",
    "stats_df.to_excel(writer, sheet_name='strategy_stats')\n",
    "writer.save()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
