{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>announcement_date</th>\n",
       "      <th>implementation_date</th>\n",
       "      <th>effective_date</th>\n",
       "      <th>ticker</th>\n",
       "      <th>name</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-12-28</td>\n",
       "      <td>2016-01-04</td>\n",
       "      <td>NaT</td>\n",
       "      <td>TW</td>\n",
       "      <td>Willis Towers Watson</td>\n",
       "      <td>ADDED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-12-28</td>\n",
       "      <td>2016-01-04</td>\n",
       "      <td>NaT</td>\n",
       "      <td>FOSL</td>\n",
       "      <td>Fossil Group</td>\n",
       "      <td>DELETED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-01-13</td>\n",
       "      <td>2016-01-15</td>\n",
       "      <td>NaT</td>\n",
       "      <td>EXR</td>\n",
       "      <td>Extra Space Storage</td>\n",
       "      <td>ADDED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-01-13</td>\n",
       "      <td>2016-01-15</td>\n",
       "      <td>NaT</td>\n",
       "      <td>CB</td>\n",
       "      <td>Chubb</td>\n",
       "      <td>DELETED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-01-22</td>\n",
       "      <td>2016-01-29</td>\n",
       "      <td>NaT</td>\n",
       "      <td>FRT</td>\n",
       "      <td>Federal Realty Trust</td>\n",
       "      <td>ADDED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>2020-02-27</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2020-03-03</td>\n",
       "      <td>XEC</td>\n",
       "      <td>Cimarex Energy</td>\n",
       "      <td>DELETED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>2020-03-31</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2020-04-03</td>\n",
       "      <td>OTIS</td>\n",
       "      <td>Otis Worldwide</td>\n",
       "      <td>ADDED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>2020-03-31</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2020-04-03</td>\n",
       "      <td>CARR</td>\n",
       "      <td>Carrier Global</td>\n",
       "      <td>ADDED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>2020-03-31</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2020-04-06</td>\n",
       "      <td>RTN</td>\n",
       "      <td>Raytheon</td>\n",
       "      <td>DELETED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>2020-03-31</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2020-04-06</td>\n",
       "      <td>M</td>\n",
       "      <td>Macy’s</td>\n",
       "      <td>DELETED</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>156 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    announcement_date implementation_date effective_date ticker  \\\n",
       "0          2015-12-28          2016-01-04            NaT     TW   \n",
       "1          2015-12-28          2016-01-04            NaT   FOSL   \n",
       "2          2016-01-13          2016-01-15            NaT    EXR   \n",
       "3          2016-01-13          2016-01-15            NaT     CB   \n",
       "4          2016-01-22          2016-01-29            NaT    FRT   \n",
       "..                ...                 ...            ...    ...   \n",
       "151        2020-02-27                 NaT     2020-03-03    XEC   \n",
       "152        2020-03-31                 NaT     2020-04-03   OTIS   \n",
       "153        2020-03-31                 NaT     2020-04-03   CARR   \n",
       "154        2020-03-31                 NaT     2020-04-06    RTN   \n",
       "155        2020-03-31                 NaT     2020-04-06      M   \n",
       "\n",
       "                     name     type  \n",
       "0    Willis Towers Watson    ADDED  \n",
       "1            Fossil Group  DELETED  \n",
       "2     Extra Space Storage    ADDED  \n",
       "3                   Chubb  DELETED  \n",
       "4    Federal Realty Trust    ADDED  \n",
       "..                    ...      ...  \n",
       "151        Cimarex Energy  DELETED  \n",
       "152        Otis Worldwide    ADDED  \n",
       "153        Carrier Global    ADDED  \n",
       "154              Raytheon  DELETED  \n",
       "155                Macy’s  DELETED  \n",
       "\n",
       "[156 rows x 6 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "from pandas_datareader import data as pdr\n",
    "yf.pdr_override() # <== that's all it takes :-)\n",
    "import numpy as np\n",
    "import statistics\n",
    "from pprint import pprint\n",
    "from math import isnan\n",
    "\n",
    "sp500_history = pd.read_excel('./sp500_rebalance_announcements.xlsx')\n",
    "sp500_history['implementation_date'] = pd.to_datetime(sp500_history['implementation_date']) \n",
    "sp500_history['effective_date'] = pd.to_datetime(sp500_history['effective_date']) \n",
    "sp500_history['announcement_date'] = pd.to_datetime(sp500_history['announcement_date']) \n",
    "sp500_history = sp500_history[['announcement_date', 'implementation_date', 'effective_date', 'ticker', 'name', 'type']]\n",
    "\n",
    "start_date = datetime.strptime('2015-12-20', '%Y-%m-%d')\n",
    "end_date = datetime.strptime('2020-12-31', '%Y-%m-%d')\n",
    "\n",
    "# greater than the start date and smaller than the end date\n",
    "mask = (sp500_history['announcement_date'] > start_date) & (sp500_history['announcement_date'] <= end_date)\n",
    "sp500_history = sp500_history.loc[mask]\n",
    "\n",
    "# Sort\n",
    "sp500_history = sp500_history.sort_values(['announcement_date', 'type'], ascending=[True, True])\n",
    "\n",
    "sp500_history = sp500_history.drop_duplicates()\n",
    "sp500_history = sp500_history.reset_index(drop=True)\n",
    "\n",
    "sp500_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.isna(sp500_history.loc[0]['effective_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[numpy.datetime64('2020-03-20T00:00:00.000000000'),\n",
      " numpy.datetime64('2020-06-19T00:00:00.000000000'),\n",
      " numpy.datetime64('2020-09-18T00:00:00.000000000'),\n",
      " numpy.datetime64('2020-12-18T00:00:00.000000000'),\n",
      " numpy.datetime64('2019-03-15T00:00:00.000000000'),\n",
      " numpy.datetime64('2019-06-21T00:00:00.000000000'),\n",
      " numpy.datetime64('2019-09-20T00:00:00.000000000'),\n",
      " numpy.datetime64('2019-12-20T00:00:00.000000000'),\n",
      " numpy.datetime64('2018-03-16T00:00:00.000000000'),\n",
      " numpy.datetime64('2018-06-15T00:00:00.000000000'),\n",
      " numpy.datetime64('2018-09-21T00:00:00.000000000'),\n",
      " numpy.datetime64('2018-12-21T00:00:00.000000000'),\n",
      " numpy.datetime64('2017-03-17T00:00:00.000000000'),\n",
      " numpy.datetime64('2017-06-16T00:00:00.000000000'),\n",
      " numpy.datetime64('2017-09-15T00:00:00.000000000'),\n",
      " numpy.datetime64('2017-12-15T00:00:00.000000000'),\n",
      " numpy.datetime64('2016-03-18T00:00:00.000000000'),\n",
      " numpy.datetime64('2016-06-17T00:00:00.000000000'),\n",
      " numpy.datetime64('2016-09-16T00:00:00.000000000'),\n",
      " numpy.datetime64('2016-12-16T00:00:00.000000000')]\n"
     ]
    }
   ],
   "source": [
    "calendar = pd.read_excel('./Nasdaq_Trading_Calendar.xlsx', sheet_name=None)\n",
    "rebal_dates = []\n",
    "for year in calendar:\n",
    "    sheet = calendar[year]\n",
    "    mask = sheet['S&P Indexes Rebalance S&P 500, S&P 400, and S&P 600'] == 1\n",
    "    year_rebal_dates = sheet.loc[mask]\n",
    "    for date in year_rebal_dates['Date'].values:\n",
    "        rebal_dates.append(date)\n",
    "pprint(rebal_dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rebal_type is 'regular' or 'ad_hoc'\n",
    "# add_delete is 'add' or 'delete'\n",
    "# entry_date and exit_date are in terms of number of days before (-) or after (+) effective date\n",
    "# entry_time and exit_time are 'Open' or 'Close'\n",
    "strategy_attributes = ['rebal_type', 'add_delete', 'entry_date', 'entry_time', 'exit_date', 'exit_time']\n",
    "\n",
    "impl_output_columns = ['implementation_date', 'effective_date']\n",
    "impl_output_columns.extend(strategy_attributes)\n",
    "impl_output_columns.extend(['total', 'up', 'count'])\n",
    "\n",
    "impl_output = pd.DataFrame(columns=impl_output_columns)\n",
    "\n",
    "ann_output_columns = ['announcement_date']\n",
    "ann_output_columns.extend(strategy_attributes)\n",
    "ann_output_columns.extend(['total', 'up', 'count'])\n",
    "\n",
    "ann_output = pd.DataFrame(columns=ann_output_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_impl_output_table(df_output, impl_date, eff_date, rebal_type, add_delete, \n",
    "                        entry_date, entry_time, exit_date, exit_time, price_change):\n",
    "    if price_change > 0:\n",
    "        up = 1\n",
    "    else:\n",
    "        up = 0\n",
    "\n",
    "    conditions = ((df_output['implementation_date']==impl_date) & \n",
    "                 (df_output['rebal_type']==rebal_type) & \n",
    "                 (df_output['add_delete']==add_delete) &\n",
    "                (df_output['entry_date']==entry_date) & \n",
    "                (df_output['entry_time']==entry_time) & \n",
    "                (df_output['exit_date']==exit_date) & \n",
    "                (df_output['exit_time']==exit_time))\n",
    "\n",
    "    # new row\n",
    "    if not conditions.any():\n",
    "        data = [{'implementation_date': impl_date, 'rebal_type': rebal_type, 'add_delete': add_delete, \n",
    "                 'entry_date': entry_date, 'entry_time': entry_time, \n",
    "                 'exit_date': exit_date, 'exit_time': exit_time, \n",
    "                 'total': price_change, 'up': up, 'count': 1, 'effective_date': eff_date}]\n",
    "        df_output = df_output.append(pd.DataFrame(data), ignore_index=True)\n",
    "\n",
    "    # updating existing row\n",
    "    else:\n",
    "        df_output.loc[conditions, 'total'] += price_change\n",
    "        df_output.loc[conditions, 'up'] += up\n",
    "        df_output.loc[conditions, 'count'] += 1\n",
    "    \n",
    "    return df_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_ann_output_table(df_output, announcement_date, rebal_type, add_delete, \n",
    "                        entry_date, entry_time, exit_date, exit_time, price_change):\n",
    "    if price_change > 0:\n",
    "        up = 1\n",
    "    else:\n",
    "        up = 0\n",
    "\n",
    "    conditions = ((df_output['announcement_date']==announcement_date) & \n",
    "                 (df_output['rebal_type']==rebal_type) & \n",
    "                 (df_output['add_delete']==add_delete) &\n",
    "                (df_output['entry_date']==entry_date) & \n",
    "                (df_output['entry_time']==entry_time) & \n",
    "                (df_output['exit_date']==exit_date) & \n",
    "                (df_output['exit_time']==exit_time))\n",
    "\n",
    "    # new row\n",
    "    if not conditions.any():\n",
    "        data = [{'announcement_date': announcement_date, 'rebal_type': rebal_type, 'add_delete': add_delete, \n",
    "                 'entry_date': entry_date, 'entry_time': entry_time, \n",
    "                 'exit_date': exit_date, 'exit_time': exit_time, \n",
    "                 'total': price_change, 'up': up, 'count': 1}]\n",
    "        df_output = df_output.append(pd.DataFrame(data), ignore_index=True)\n",
    "\n",
    "    # updating existing row\n",
    "    else:\n",
    "        df_output.loc[conditions, 'total'] += price_change\n",
    "        df_output.loc[conditions, 'up'] += up\n",
    "        df_output.loc[conditions, 'count'] += 1\n",
    "    \n",
    "    return df_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_price_at_index(prices, date_index, index_offset, time_of_day):\n",
    "    '''\n",
    "    Returns -1 if index not valid\n",
    "    '''\n",
    "    adj_index = date_index + index_offset\n",
    "    if adj_index < 0 or adj_index >= len(prices):\n",
    "        return -1\n",
    "    price = prices.iloc[adj_index][time_of_day]\n",
    "    if isnan(price):\n",
    "        return -1\n",
    "    return price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_price_change(prices, date_index, entry_date, entry_time, exit_date, exit_time):\n",
    "    '''\n",
    "    Returns percentage change in price between entry and exit\n",
    "    Or NaN if anything invalid\n",
    "    '''\n",
    "    entry_price = find_price_at_index(prices, date_index, entry_date, entry_time)\n",
    "    if entry_price < 0 or isnan(entry_price):\n",
    "        return float('NaN')\n",
    "    exit_price = find_price_at_index(prices, date_index, exit_date, exit_time)\n",
    "    if exit_price < 0 or isnan(exit_price):\n",
    "        return float('NaN')\n",
    "    return exit_price / entry_price - 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- TW: Data doesn't exist for startDate = 1450108800, endDate = 1453651200\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- BRCM: No data found for this date range, symbol may be delisted\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- PCP: Data doesn't exist for startDate = 1452268800, endDate = 1455811200\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- GMCR: No data found for this date range, symbol may be delisted\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- CAM: No data found for this date range, symbol may be delisted\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- SNDK: No data found for this date range, symbol may be delisted\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- TWC: No data found for this date range, symbol may be delisted\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- ARG: Data doesn't exist for startDate = 1461945600, endDate = 1465488000\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- CCE: No data found for this date range, symbol may be delisted\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- CVC: No data found for this date range, symbol may be delisted\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- TE: No data found for this date range, symbol may be delisted\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- CPGX: No data found for this date range, symbol may be delisted\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- STJ: No data found for this date range, symbol may be delisted\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- LLTC: No data found for this date range, symbol may be delisted\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- YHOO: No data found for this date range, symbol may be delisted\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- MJN: No data found for this date range, symbol may be delisted\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- Q: No data found for this date range, symbol may be delisted\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- WFM: No data found for this date range, symbol may be delisted\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- SPLS: No data found for this date range, symbol may be delisted\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- LVLT: No data found for this date range, symbol may be delisted\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- BCR: No data found for this date range, symbol may be delisted\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- WYN: No data found for this date range, symbol may be delisted\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- DPS: No data found for this date range, symbol may be delisted\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- GGP: No data found for this date range, symbol may be delisted\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- WCG: No data found, symbol may be delisted\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- FOXAV: No data found, symbol may be delisted\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- FOXBV: No data found, symbol may be delisted\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- LLL: No data found, symbol may be delisted\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- RHT: No data found, symbol may be delisted\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- APC: No data found, symbol may be delisted\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- VIAB: No data found, symbol may be delisted\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- WCG: No data found, symbol may be delisted\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "days_bef_aft = 20 # the range of days before and after effective date to pull from Yahoo finance\n",
    "\n",
    "exit_time = 'Close'\n",
    "\n",
    "times_of_day = ['Open', 'Close']\n",
    "\n",
    "has_impl_date = False\n",
    "\n",
    "for idx, row in sp500_history.iterrows():\n",
    "    # Has implementation date, but not effective date\n",
    "    if pd.isna(row['effective_date']) and not pd.isna(row['implementation_date']):\n",
    "        has_impl_date = True\n",
    "        impl_date = row['implementation_date']\n",
    "\n",
    "    # Has effective date but not implementation date\n",
    "    elif pd.isna(row['implementation_date']) and not pd.isna(row['effective_date']):\n",
    "        has_impl_date = False\n",
    "        eff_date = row['effective_date']\n",
    "        \n",
    "    else:\n",
    "        print(\"Error: Has neither implementation or effective date.\")\n",
    "        print(row)\n",
    "        continue\n",
    "    \n",
    "    tickers = row['ticker'].split(';')\n",
    "    for ticker in tickers:\n",
    "        \n",
    "        # End date is exclusive, so need to increase by 1\n",
    "        if has_impl_date:\n",
    "            impl_prices = pdr.get_data_yahoo(ticker, start=impl_date - timedelta(days=days_bef_aft), end=impl_date + timedelta(days=days_bef_aft + 1))\n",
    "        else:\n",
    "            impl_prices = pdr.get_data_yahoo(ticker, start=eff_date - timedelta(days=days_bef_aft), end=eff_date + timedelta(days=days_bef_aft + 1))\n",
    "        \n",
    "        if len(impl_prices) == 0:\n",
    "            continue\n",
    "\n",
    "        # Find the implementation date or effective date whichever is not available in the data\n",
    "        if has_impl_date:\n",
    "            try:\n",
    "                eff_date_index = impl_prices.index.get_loc(impl_date + timedelta(days=1),method='backfill')\n",
    "            except:\n",
    "                print(\"Error: No date after implementation date was found among yahoo impl_prices\")\n",
    "                print(impl_date)\n",
    "                continue\n",
    "            if eff_date_index < 0:\n",
    "                continue\n",
    "            eff_date = impl_prices.iloc[eff_date_index].name\n",
    "\n",
    "        else:\n",
    "            try:\n",
    "                impl_date_index = impl_prices.index.get_loc(eff_date - timedelta(days=1),method='pad')\n",
    "            except:\n",
    "                print(\"Error: No date before effective date was found among yahoo impl_prices\")\n",
    "                print(eff_date)\n",
    "                continue\n",
    "            if impl_date_index < 0:\n",
    "        #         print('implementation date not in range')\n",
    "        #         print(impl_prices)\n",
    "        #         print(row['effective_date'])\n",
    "                continue\n",
    "            impl_date = impl_prices.iloc[impl_date_index].name\n",
    "    #     print(\"sanity check:\")\n",
    "    #     print(\"impl date:\")\n",
    "    #     print(impl_date)\n",
    "    #     print(\"eff date:\")\n",
    "    #     print(row['effective_date'])\n",
    "\n",
    "        if impl_date in rebal_dates:\n",
    "            rebal_type = 'regular'\n",
    "    #         print(\"regular!\")\n",
    "    #         print(impl_prices)\n",
    "    #         print(impl_date)\n",
    "        else:\n",
    "            rebal_type = 'ad_hoc'\n",
    "\n",
    "        if row['type'] == 'ADDED':\n",
    "            add_delete = 'add'\n",
    "        else:\n",
    "            add_delete = 'delete'\n",
    "\n",
    "        '''\n",
    "        Loop of different entry and exit dates for implementation date\n",
    "        '''\n",
    "        entry_date = max(-4, -impl_date_index)\n",
    "        exit_date = 0\n",
    "        while entry_date < 0:\n",
    "            for time_of_day in times_of_day:\n",
    "                entry_time = time_of_day\n",
    "\n",
    "                price_change = find_price_change(impl_prices, impl_date_index, entry_date, entry_time, exit_date, exit_time)\n",
    "                if isnan(price_change):\n",
    "    #                 print(\"price change is invalid\")\n",
    "    #                 print(price_change)\n",
    "                    continue\n",
    "\n",
    "    #             if price_change == 0:\n",
    "    #                 print('WHY EQUAL')\n",
    "    #                 print(impl_prices)\n",
    "    #                 print(entry_price)\n",
    "    #                 print(exit_price)\n",
    "\n",
    "                impl_output = update_impl_output_table(impl_output, impl_date, eff_date, rebal_type, add_delete, \n",
    "                            entry_date, entry_time, exit_date, exit_time, price_change)\n",
    "\n",
    "            entry_date += 1\n",
    "\n",
    "        entry_date = 0\n",
    "        exit_date = min(4, len(impl_prices) - 1)\n",
    "        while exit_date > 0:\n",
    "            for time_of_day in times_of_day:\n",
    "                entry_time = time_of_day\n",
    "\n",
    "                price_change = find_price_change(impl_prices, impl_date_index, entry_date, entry_time, exit_date, exit_time)\n",
    "                if isnan(price_change):\n",
    "    #                 print(\"price change is invalid\")\n",
    "    #                 print(price_change)\n",
    "                    continue\n",
    "\n",
    "                impl_output = update_impl_output_table(impl_output, impl_date, eff_date, rebal_type, add_delete, \n",
    "                            entry_date, entry_time, exit_date, exit_time, price_change)\n",
    "\n",
    "            exit_date -= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_uniques(input_list):\n",
    "    # insert the list to the set \n",
    "    unique_set = set(input_list) \n",
    "    # convert the set to the list \n",
    "    unique_list = (list(unique_set)) \n",
    "    return unique_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Calculate population statistics\n",
    "'''\n",
    "\n",
    "stats_df_columns = []\n",
    "stats_df_columns.extend(strategy_attributes)\n",
    "stats_df_columns.extend(['total', 'up', 'count', 'mean', 'std', 'max', 'min', 'sharpe', 'uppct'])\n",
    "\n",
    "stats_df = pd.DataFrame(columns=stats_df_columns)\n",
    "\n",
    "# get the unique values for each strategy attribute\n",
    "strategy_attribute_unique_values = map(lambda strategy_attribute: get_uniques(impl_output[strategy_attribute]), strategy_attributes)   \n",
    "\n",
    "import itertools\n",
    "# find strategies consisting of different combinations of unique values for each strategy attribute\n",
    "strategies = list(itertools.product(*strategy_attribute_unique_values)) \n",
    "\n",
    "for strategy in strategies:\n",
    "    # find the relevant rows for each strategy \n",
    "    relevant_rows = impl_output.loc[(impl_output[strategy_attributes]==strategy).all(axis=1), :]\n",
    "    if len(relevant_rows) == 0:\n",
    "        continue\n",
    "    \n",
    "    relevant_rows_sum = relevant_rows.loc[:, 'total':].sum(axis=0)\n",
    "    mean = relevant_rows_sum['total'] / relevant_rows_sum['count']\n",
    "    if relevant_rows_sum['count'] > 1:\n",
    "        std = statistics.stdev(relevant_rows['total'])\n",
    "    else:\n",
    "        std = 0\n",
    "    max_val = max(relevant_rows['total'])\n",
    "    min_val = min(relevant_rows['total'])\n",
    "    if std == 0:\n",
    "        sharpe = mean / 0.00001 * np.sqrt(252)\n",
    "    else:\n",
    "        sharpe = mean / std * np.sqrt(252)\n",
    "    uppct = relevant_rows_sum['up'] / relevant_rows_sum['count']\n",
    "    strategy_dict = dict(zip(strategy_attributes, strategy)) \n",
    "    data = {'total': relevant_rows_sum['total'], 'up': relevant_rows_sum['up'], 'count': relevant_rows_sum['count'], \n",
    "            'mean': mean, 'std': std, 'max': max_val, 'min': min_val, 'sharpe': sharpe, 'uppct': uppct} \n",
    "    data.update(strategy_dict)\n",
    "    stats_df = stats_df.append(pd.DataFrame([data]), ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Writing to excel\n",
    "'''\n",
    "writer = pd.ExcelWriter('sp500_impl_analysis.xlsx', engine='xlsxwriter')\n",
    "impl_output.to_excel(writer, sheet_name='data')\n",
    "stats_df.to_excel(writer, sheet_name='strategy_stats')\n",
    "writer.save()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
