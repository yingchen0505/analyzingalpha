{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>value</th>\n",
       "      <th>variable</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>2016-01-05</td>\n",
       "      <td>WLTW</td>\n",
       "      <td>added_ticker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>2016-01-05</td>\n",
       "      <td>FOSL</td>\n",
       "      <td>removed_ticker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262</th>\n",
       "      <td>2016-01-19</td>\n",
       "      <td>EXR</td>\n",
       "      <td>added_ticker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>2016-01-19</td>\n",
       "      <td>CB</td>\n",
       "      <td>removed_ticker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264</th>\n",
       "      <td>2016-02-01</td>\n",
       "      <td>FRT</td>\n",
       "      <td>added_ticker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>453</th>\n",
       "      <td>2019-12-23</td>\n",
       "      <td>ZBRA</td>\n",
       "      <td>added_ticker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>454</th>\n",
       "      <td>2019-12-23</td>\n",
       "      <td>STE</td>\n",
       "      <td>added_ticker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>449</th>\n",
       "      <td>2019-12-23</td>\n",
       "      <td>AMG</td>\n",
       "      <td>removed_ticker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>451</th>\n",
       "      <td>2019-12-23</td>\n",
       "      <td>MAC</td>\n",
       "      <td>removed_ticker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>452</th>\n",
       "      <td>2019-12-23</td>\n",
       "      <td>TRIP</td>\n",
       "      <td>removed_ticker</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>195 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          date value        variable\n",
       "261 2016-01-05  WLTW    added_ticker\n",
       "260 2016-01-05  FOSL  removed_ticker\n",
       "262 2016-01-19   EXR    added_ticker\n",
       "263 2016-01-19    CB  removed_ticker\n",
       "264 2016-02-01   FRT    added_ticker\n",
       "..         ...   ...             ...\n",
       "453 2019-12-23  ZBRA    added_ticker\n",
       "454 2019-12-23   STE    added_ticker\n",
       "449 2019-12-23   AMG  removed_ticker\n",
       "451 2019-12-23   MAC  removed_ticker\n",
       "452 2019-12-23  TRIP  removed_ticker\n",
       "\n",
       "[195 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "from pandas_datareader import data as pdr\n",
    "yf.pdr_override() # <== that's all it takes :-)\n",
    "import numpy as np\n",
    "import statistics\n",
    "from pprint import pprint\n",
    "from math import isnan\n",
    "\n",
    "sp500_history = pd.read_csv('./sp500_history.csv')\n",
    "sp500_history['date'] = pd.to_datetime(sp500_history['date']) \n",
    "sp500_history = sp500_history[['date', 'value', 'variable']]\n",
    "\n",
    "start_date = datetime.strptime('2016-1-1', '%Y-%m-%d')\n",
    "end_date = datetime.strptime('2020-12-31', '%Y-%m-%d')\n",
    "\n",
    "# greater than the start date and smaller than the end date\n",
    "mask = (sp500_history['date'] > start_date) & (sp500_history['date'] <= end_date)\n",
    "sp500_history = sp500_history.loc[mask]\n",
    "\n",
    "# Sort\n",
    "sp500_history.sort_values(['date', 'variable'], ascending=[True, True])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[numpy.datetime64('2020-03-20T00:00:00.000000000'),\n",
      " numpy.datetime64('2020-06-19T00:00:00.000000000'),\n",
      " numpy.datetime64('2020-09-18T00:00:00.000000000'),\n",
      " numpy.datetime64('2020-12-18T00:00:00.000000000'),\n",
      " numpy.datetime64('2019-03-15T00:00:00.000000000'),\n",
      " numpy.datetime64('2019-06-21T00:00:00.000000000'),\n",
      " numpy.datetime64('2019-09-20T00:00:00.000000000'),\n",
      " numpy.datetime64('2019-12-20T00:00:00.000000000'),\n",
      " numpy.datetime64('2018-03-16T00:00:00.000000000'),\n",
      " numpy.datetime64('2018-06-15T00:00:00.000000000'),\n",
      " numpy.datetime64('2018-09-21T00:00:00.000000000'),\n",
      " numpy.datetime64('2018-12-21T00:00:00.000000000'),\n",
      " numpy.datetime64('2017-03-17T00:00:00.000000000'),\n",
      " numpy.datetime64('2017-06-16T00:00:00.000000000'),\n",
      " numpy.datetime64('2017-09-15T00:00:00.000000000'),\n",
      " numpy.datetime64('2017-12-15T00:00:00.000000000'),\n",
      " numpy.datetime64('2016-03-18T00:00:00.000000000'),\n",
      " numpy.datetime64('2016-06-17T00:00:00.000000000'),\n",
      " numpy.datetime64('2016-09-16T00:00:00.000000000'),\n",
      " numpy.datetime64('2016-12-16T00:00:00.000000000')]\n"
     ]
    }
   ],
   "source": [
    "calendar = pd.read_excel('./Nasdaq_Trading_Calendar.xlsx', sheet_name=None)\n",
    "rebal_dates = []\n",
    "for year in calendar:\n",
    "    sheet = calendar[year]\n",
    "    mask = sheet['S&P Indexes Rebalance S&P 500, S&P 400, and S&P 600'] == 1\n",
    "    year_rebal_dates = sheet.loc[mask]\n",
    "    for date in year_rebal_dates['Date'].values:\n",
    "        rebal_dates.append(date)\n",
    "pprint(rebal_dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rebal_type is 'regular' or 'ad_hoc'\n",
    "# add_delete is 'add' or 'delete'\n",
    "# entry_date and exit_date are in terms of number of days before (-) or after (+) effective date\n",
    "# entry_time and exit_time are 'Open' or 'Close'\n",
    "strategy_attributes = ['rebal_type', 'add_delete', 'entry_date', 'entry_time', 'exit_date', 'exit_time']\n",
    "\n",
    "output_columns = ['eff_date', 'original_date']\n",
    "output_columns.extend(strategy_attributes)\n",
    "output_columns.extend(['total', 'up', 'count'])\n",
    "\n",
    "df_output = pd.DataFrame(columns=output_columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yingchen\\Anaconda3\\envs\\finance\\lib\\site-packages\\ipykernel_launcher.py:112: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- BRCM: No data found for this date range, symbol may be delisted\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- PCP: Data doesn't exist for startDate = 1452528000, endDate = 1456070400\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- GMCR: No data found for this date range, symbol may be delisted\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- ESV: No data found, symbol may be delisted\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- CAM: No data found for this date range, symbol may be delisted\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- ADT: Data doesn't exist for startDate = 1460476800, endDate = 1464019200\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- SNDK: No data found for this date range, symbol may be delisted\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- TWC: No data found for this date range, symbol may be delisted\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- ARG: Data doesn't exist for startDate = 1462204800, endDate = 1465747200\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- CCE: Data doesn't exist for startDate = 1462896000, endDate = 1466438400\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- BXLT: No data found for this date range, symbol may be delisted\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- CVC: No data found for this date range, symbol may be delisted\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- TE: No data found for this date range, symbol may be delisted\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- CPGX: No data found for this date range, symbol may be delisted\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- STJ: No data found for this date range, symbol may be delisted\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- SE: Data doesn't exist for startDate = 1486483200, endDate = 1490025600\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- LLTC: No data found for this date range, symbol may be delisted\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- MJN: No data found for this date range, symbol may be delisted\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- YHOO: No data found for this date range, symbol may be delisted\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- RAI: No data found for this date range, symbol may be delisted\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- WFM: No data found for this date range, symbol may be delisted\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- Q: No data found for this date range, symbol may be delisted\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- SPLS: No data found for this date range, symbol may be delisted\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- LVLT: No data found for this date range, symbol may be delisted\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- BCR: No data found for this date range, symbol may be delisted\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- WYN: No data found for this date range, symbol may be delisted\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- DPS: No data found for this date range, symbol may be delisted\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- GGP: No data found for this date range, symbol may be delisted\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- BMS: No data found, symbol may be delisted\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- LLL: No data found, symbol may be delisted\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- RHT: No data found, symbol may be delisted\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- APC: No data found, symbol may be delisted\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- TSS: No data found, symbol may be delisted\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "MAX_DATE_EXTENSION = 10\n",
    "days_bef_aft = 20 # the range of days before and after effective date to pull from Yahoo finance\n",
    "last_date = sp500_history.iloc[0, sp500_history.columns.get_loc('date')]\n",
    "last_changes = []\n",
    "is_begin = True\n",
    "\n",
    "rebal_type = ''\n",
    "last_rebal_type = ''\n",
    "\n",
    "add_delete = ''\n",
    "last_add_delete = ''\n",
    "\n",
    "entry_date = -1\n",
    "entry_time = 'Close'\n",
    "exit_date = 0\n",
    "exit_time = 'Close'\n",
    "\n",
    "for idx, row in sp500_history.iterrows():\n",
    "    \n",
    "    # End date is exclusive, so need to increase by 1\n",
    "    prices = pdr.get_data_yahoo(row['value'], start=row['date'] - timedelta(days=days_bef_aft), end=row['date'] + timedelta(days=days_bef_aft + 1))\n",
    "    if len(prices) == 0:\n",
    "        continue\n",
    "        \n",
    "    # Find the adjusted effective date \n",
    "    # which is one trading day before the wikipedia effective (i.e. market opening) date\n",
    "    eff_date_index = prices.index.get_loc(row['date'],method='pad')\n",
    "    if eff_date_index < 0:\n",
    "        print('SOMETHINGS WRONG')\n",
    "        print(prices)\n",
    "        print(row['date'])\n",
    "        continue\n",
    "#     print(prices)\n",
    "#     print(eff_date_index)\n",
    "    eff_date = prices.iloc[eff_date_index].name\n",
    "#     print(eff_date)\n",
    "    \n",
    "#     if row['date'] not in prices.index:\n",
    "#         print('SOMETHINGS WRONG')\n",
    "#         print(prices)\n",
    "#         print(row['date'])\n",
    "#         continue\n",
    "        \n",
    "#     eff_date = row['date'] - timedelta(days=1)\n",
    "#     date_extension = 0\n",
    "#     while not eff_date in prices.index and date_extension < MAX_DATE_EXTENSION:\n",
    "#         eff_date -= timedelta(days=1)\n",
    "#         date_extension += 1\n",
    "#     if date_extension >= MAX_DATE_EXTENSION:\n",
    "#         continue\n",
    "    eff_date_close = prices.loc[eff_date][entry_time]\n",
    "    if isnan(eff_date_close):\n",
    "        continue\n",
    "        \n",
    "    # Find the entry date, which is one trading day before the adjusted effective date\n",
    "    prev_date = eff_date - timedelta(days=1)\n",
    "    date_extension = 0\n",
    "    while not prev_date in prices.index and date_extension < MAX_DATE_EXTENSION:\n",
    "        prev_date -= timedelta(days=1)\n",
    "        date_extension += 1\n",
    "    if date_extension >= MAX_DATE_EXTENSION:\n",
    "        continue\n",
    "    prev_close = prices.loc[prev_date][exit_time]\n",
    "    if isnan(prev_close):\n",
    "        continue\n",
    "\n",
    "    price_change = eff_date_close / prev_close - 1 # percentage change in price between entry and exit\n",
    "    \n",
    "    if eff_date in rebal_dates:\n",
    "        rebal_type = 'regular'\n",
    "            \n",
    "    else:\n",
    "        rebal_type = 'ad_hoc'\n",
    "\n",
    "    if row['variable'] == 'added_ticker':\n",
    "        add_delete = 'add'\n",
    "    else:\n",
    "        add_delete = 'delete'\n",
    "\n",
    "    # Calculate mean and all\n",
    "    if not is_begin and (last_date != eff_date or last_add_delete != add_delete):\n",
    "        count = len(last_changes)\n",
    "        up = len(list(filter(lambda x: (x >= 0), last_changes))) \n",
    "        \n",
    "        data = [up, count]\n",
    "\n",
    "        df_output.loc[(df_output['eff_date']==last_date) & \n",
    "                 (df_output['rebal_type']==last_rebal_type) & \n",
    "                 (df_output['add_delete']==last_add_delete), 'up':] = data\n",
    "\n",
    "        total = 0\n",
    "        last_changes = []\n",
    "    \n",
    "    # Still in the same date\n",
    "    else:\n",
    "        if is_begin:\n",
    "            total = 0\n",
    "            is_begin = False\n",
    "        else:\n",
    "            total = last_row['total']\n",
    "    \n",
    "    total += price_change\n",
    "    \n",
    "    data = [{'eff_date': pd.to_datetime(eff_date), 'rebal_type': rebal_type, 'add_delete': add_delete, \n",
    "             'entry_date': entry_date, 'entry_time': entry_time, \n",
    "             'exit_date': exit_date, 'exit_time': exit_time, \n",
    "             'total': total, 'original_date': row['date']}]\n",
    "            \n",
    "    if not (df_output['eff_date']==eff_date).any():\n",
    "        df_output = df_output.append(pd.DataFrame(data), ignore_index=True)\n",
    "    else:\n",
    "        df_output[df_output['eff_date']==eff_date]['total'] = total\n",
    "\n",
    "    last_date = eff_date\n",
    "    last_changes.append(price_change)\n",
    "    last_add_delete = add_delete\n",
    "    last_rebal_type = rebal_type\n",
    "    last_row = df_output[(df_output['eff_date']==last_date) & \n",
    "                         (df_output['rebal_type']==rebal_type) & \n",
    "                         (df_output['add_delete']==add_delete)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume'], dtype='object')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eff_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2016-01-05 00:00:00')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prices.iloc[eff_date_index].name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_uniques(input_list):\n",
    "    # insert the list to the set \n",
    "    unique_set = set(input_list) \n",
    "    # convert the set to the list \n",
    "    unique_list = (list(unique_set)) \n",
    "    return unique_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Calculate population statistics\n",
    "'''\n",
    "\n",
    "stats_df_columns = []\n",
    "stats_df_columns.extend(strategy_attributes)\n",
    "stats_df_columns.extend(['total', 'up', 'count', 'mean', 'std', 'max', 'min', 'sharpe', 'uppct'])\n",
    "\n",
    "stats_df = pd.DataFrame(columns=stats_df_columns)\n",
    "\n",
    "# get the unique values for each strategy attribute\n",
    "strategy_attribute_unique_values = map(lambda strategy_attribute: get_uniques(df_output[strategy_attribute]), strategy_attributes)   \n",
    "\n",
    "import itertools\n",
    "# find strategies consisting of different combinations of unique values for each strategy attribute\n",
    "strategies = list(itertools.product(*strategy_attribute_unique_values)) \n",
    "\n",
    "for strategy in strategies:\n",
    "    # find the relevant rows for each strategy \n",
    "    relevant_rows = df_output.loc[(df_output[strategy_attributes]==strategy).all(axis=1), :]\n",
    "    \n",
    "    relevant_rows_sum = relevant_rows.loc[:, 'total':].sum(axis=0)\n",
    "    mean = relevant_rows_sum['total'] / relevant_rows_sum['count']\n",
    "    if relevant_rows_sum['count'] > 1:\n",
    "        std = statistics.stdev(relevant_rows['total'])\n",
    "    else:\n",
    "        std = 0\n",
    "    max_val = max(relevant_rows['total'])\n",
    "    min_val = min(relevant_rows['total'])\n",
    "    if std == 0:\n",
    "        sharpe = mean / 0.00001 * np.sqrt(252)\n",
    "    else:\n",
    "        sharpe = mean / std * np.sqrt(252)\n",
    "    uppct = relevant_rows_sum['up'] / relevant_rows_sum['count']\n",
    "    strategy_dict = dict(zip(strategy_attributes, strategy)) \n",
    "    data = {'total': relevant_rows_sum['total'], 'up': relevant_rows_sum['up'], 'count': relevant_rows_sum['count'], \n",
    "            'mean': mean, 'std': std, 'max': max_val, 'min': min_val, 'sharpe': sharpe, 'uppct': uppct} \n",
    "    data.update(strategy_dict)\n",
    "    stats_df = stats_df.append(pd.DataFrame([data]), ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Writing to excel\n",
    "'''\n",
    "writer = pd.ExcelWriter('sp500_analysis.xlsx', engine='xlsxwriter')\n",
    "df_output.to_excel(writer, sheet_name='data')\n",
    "stats_df.to_excel(writer, sheet_name='strategy_stats')\n",
    "writer.save()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
